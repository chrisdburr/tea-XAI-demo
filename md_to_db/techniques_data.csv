Technique,Description,Categories,Sub-Categories,Scope Global,Scope Local,Model-Dependency,Example Use-Case,Tags
SHAP (SHapley Additive exPlanations),"Assigns importance values to each feature by computing their contribution to individual predictions, based on Shapley values from cooperative game theory.",Feature Analysis,Importance and Attribution,Yes,Yes,Model-Agnostic,Explaining individual predictions in complex models like neural networks or ensemble models.,Attribution; Feature Importance; Global Scope; Local Scope; Model-Agnostic
Permutation Importance,Evaluates feature importance by measuring the decrease in model accuracy when a feature's values are randomly shuffled.,Feature Analysis,Importance and Attribution,Yes,No,Model-Agnostic,"Assessing feature importance in models where coefficients are not available, such as tree-based models.",Attribution; Feature Importance; Global Scope; Model-Agnostic
Mean Decrease Impurity (MDI),Calculates feature importance in tree-based models by measuring how much each feature decreases impurity across all trees.,Feature Analysis,Importance and Attribution,Yes,No,Model-Specific,Determining important features in Random Forest classification tasks.,Attribution; Feature Importance; Global Scope; Model-Specific
Gini Importance,Measures the total reduction of Gini impurity brought by a feature across all nodes and trees in decision trees and Random Forests.,Feature Analysis,Importance and Attribution,Yes,No,Model-Specific,Selecting important features when building tree-based classification models.,Attribution; Feature Importance; Global Scope; Model-Specific
Coefficient Magnitudes (in Linear Models),"Uses the absolute values of coefficients in linear models to represent feature importance, indicating the strength and direction of relationships.",Feature Analysis,Importance and Attribution,Yes,No,Model-Specific,Interpreting which features influence housing price predictions in linear regression.,Attribution; Feature Importance; Global Scope; Model-Specific
Integrated Gradients,Attributes feature importance by integrating gradients of the model's output with respect to inputs along a path from a baseline to the actual input. Produces visualisations of attributions.,Feature Analysis; Visualisation Techniques,Importance and Attribution; Feature Visualisation,No,Yes,Model-Specific,Understanding pixel contributions in image classification with deep neural networks.,Attribution; Feature Importance; Feature Visualisation; Local Scope; Model-Specific; Visualisation
DeepLIFT,"Tracks changes in the output relative to a reference input, decomposing contributions from individual neurons to the final prediction in deep learning models.",Feature Analysis,Importance and Attribution,No,Yes,Model-Specific,Explaining why a neural network classifies an image as a specific object by tracing neuron activations.,Attribution; Feature Importance; Local Scope; Model-Specific
Layer-wise Relevance Propagation (LRP),"Explains predictions by backpropagating relevance scores from the output layer to input features, distributing the prediction score layer by layer.",Feature Analysis,Importance and Attribution,No,Yes,Model-Specific,Visualizing important regions in medical images for disease diagnosis using deep learning models.,Attribution; Feature Importance; Local Scope; Model-Specific
"Variable Importance in Random Forests (MDA, MDG)",Calculates feature importance by measuring the Mean Decrease Accuracy or Mean Decrease Gini when a feature is excluded from Random Forest models.,Feature Analysis,Importance and Attribution,Yes,No,Model-Specific,Identifying key predictors in a Random Forest model for credit scoring.,Attribution; Feature Importance; Global Scope; Model-Specific
Contextual Decomposition,Interprets neural networks by decomposing activations to explain predictions based on contributions of individual features or groups.,Feature Analysis,Importance and Attribution,No,Yes,Model-Specific,Explaining sentiment predictions in text by attributing scores to words or phrases.,Attribution; Feature Importance; Local Scope; Model-Specific
Taylor Decomposition,Decomposes predictions into contributions from individual features using a Taylor series expansion of the model's prediction function.,Feature Analysis,Importance and Attribution,No,Yes,Model-Specific,Attributing feature contributions in complex models for specific predictions.,Attribution; Feature Importance; Local Scope; Model-Specific
Sobol Indices,Quantifies the contribution of individual variables and their interactions to the output variance in sensitivity analysis.,Feature Analysis,Interaction Analysis,Yes,No,Model-Agnostic,Understanding parameter impacts in environmental modeling outputs.,Feature Importance; Global Scope; Interaction Analysis; Model-Agnostic
Feature Interaction Detection (H-statistic),Measures feature interaction by comparing joint contributions to the model with the sum of individual contributions.,Feature Analysis,Interaction Analysis,Yes,No,Model-Agnostic,Identifying significant interactions in healthcare predictive models.,Feature Importance; Global Scope; Interaction Analysis; Model-Agnostic
LIME (Local Interpretable Model-Agnostic Explanations),Generates local surrogate models that approximate complex model behaviour around a specific instance using interpretable models like linear models. Also provides feature importance explanations.,Model Approximation; Feature Analysis,Local Surrogates; Importance and Attribution,No,Yes,Model-Agnostic,Explaining why a customer was denied a loan by approximating the model's decision locally.,Attribution; Feature Importance; Local Scope; Local Surrogate; Model-Agnostic; Surrogate Models
Ridge Regression Surrogates,"Uses Ridge Regression as a surrogate to approximate global behaviour of complex models, balancing simplicity and interpretability with regularisation. May also highlight important features.",Model Approximation,Global Surrogates,Yes,No,Model-Agnostic,Summarising complex model behaviour for regulatory reporting in finance.,Global Scope; Global Surrogate; Model-Agnostic; Surrogate Models
Partial Dependence Plots (PDP),"Visualises the relationship between one or two features and the predicted outcome, averaging out effects of other features.",Visualisation Techniques,Feature Visualisation,Yes,No,Model-Agnostic,Understanding how changes in age affect predicted disease risk in medical models.,Feature Visualisation; Global Scope; Model-Agnostic; Visualisation
Accumulated Local Effects (ALE) Plots,"Similar to PDPs but account for feature interactions, providing accurate insights when features are correlated.",Visualisation Techniques,Feature Visualisation,Yes,No,Model-Agnostic,Exploring the effect of house size on price predictions in real estate models with correlated features.,Feature Visualisation; Global Scope; Model-Agnostic; Visualisation
Individual Conditional Expectation (ICE) Plots,"Shows how a feature affects predictions for individual instances, highlighting heterogeneous effects across data points.",Visualisation Techniques,Feature Visualisation,No,Yes,Model-Agnostic,Visualising how customers' predicted spending changes with income in consumer behaviour models.,Feature Visualisation; Local Scope; Model-Agnostic; Visualisation
Saliency Maps,Highlights important pixels in input images that most influence the output prediction in computer vision models.,Visualisation Techniques; Feature Analysis,Model Behaviour Visualisation; Importance and Attribution,No,Yes,Model-Specific,Identifying regions contributing to tumor diagnosis in medical images.,Attribution; Feature Importance; Local Scope; Model-Specific; Visualisation
Grad-CAM (Gradient-weighted Class Activation Mapping),Uses gradients to produce heatmaps highlighting image regions that contribute most to the model's output.,Visualisation Techniques,Model Behaviour Visualisation,No,Yes,Model-Specific,Visualising parts of an image leading to a 'dog' classification in image recognition models.,Local Scope; Model-Specific; Visualisation
Occlusion Sensitivity,Measures prediction changes by systematically occluding parts of the input to identify important regions or features.,Visualisation Techniques; Feature Analysis,Model Behaviour Visualisation; Importance and Attribution,No,Yes,Model-Specific,Understanding which words affect sentiment prediction by masking them in NLP models.,Attribution; Feature Importance; Local Scope; Model-Specific; Visualisation
Attention Mechanisms in Neural Networks,"Visualises attention weights in models like transformers, highlighting important input parts for predictions. Attention weights can also indicate feature importance.",Visualisation Techniques; Feature Analysis,Model Behaviour Visualisation; Importance and Attribution,No,Yes,Model-Specific,Analysing which words a transformer model focuses on during machine translation tasks.,Attribution; Feature Importance; Local Scope; Model-Specific; Visualisation
Factor Analysis,"Reduces dimensionality by identifying latent factors explaining observed variability, aiding in data interpretation beyond visualisation.",Model Simplification; Visualisation Techniques,Model Distillation; Dimensionality Reduction Visualisation,Yes,No,Model-Agnostic,Discovering underlying factors in psychological survey data for social science research.,Dimensionality Reduction; Global Scope; Model Distillation; Model Simplification; Model-Agnostic; Visualisation
Principal Component Analysis (PCA),"Reduces dimensionality by projecting data onto directions of maximum variance, simplifying data while retaining important information.",Visualisation Techniques,Dimensionality Reduction Visualisation,Yes,No,Model-Agnostic,Visualising high-dimensional gene expression data in bioinformatics.,Dimensionality Reduction; Global Scope; Model-Agnostic; Visualisation
t-SNE,"A non-linear technique that visualises high-dimensional data in 2D or 3D, preserving local relationships between points.",Visualisation Techniques,Dimensionality Reduction Visualisation,Yes,No,Model-Agnostic,Visualizing clusters in high-dimensional word embeddings.,Dimensionality Reduction; Global Scope; Model-Agnostic; Visualisation
UMAP,A non-linear technique similar to t-SNE but better at preserving global data structure.,Visualisation Techniques,Dimensionality Reduction Visualisation,Yes,No,Model-Agnostic,Visualising patterns in user behaviour data for marketing analysis.,Dimensionality Reduction; Global Scope; Model-Agnostic; Visualisation
Prototype and Criticism Models,Identifies representative (prototypes) and non-representative (criticisms) examples to summarise and highlight model behaviour.,Example-Based Methods,Prototype and Criticism Methods,Yes,No,Model-Agnostic,Selecting representative customer profiles for targeted marketing.,Example-Based; Global Scope; Model-Agnostic
Influence Functions,Measures the impact of training examples on model predictions to identify influential data points.,Example-Based Methods,Prototype and Criticism Methods,Yes,No,Model-Agnostic,Debugging model predictions by identifying influential training data points.,Example-Based; Global Scope; Model-Agnostic
Contrastive Explanation Method (CEM),"Generates explanations by identifying minimal input changes that result in different outcomes, offering counterfactual reasoning.",Example-Based Methods,Counterfactual Explanations,No,Yes,Model-Agnostic,Explaining loan rejections by showing what changes would lead to approval.,Counterfactual; Example-Based; Local Scope; Model-Agnostic
"Bayesian Networks (e.g., bnlearn)",Probabilistic graphical models representing variables and their conditional dependencies for causal reasoning.,Example-Based Methods,Causal Analysis,Yes,No,Model-Specific,Modeling causal relationships in gene regulatory networks.,Causal Analysis; Example-Based; Global Scope; Model-Specific
ANCHOR,"Provides high-precision if-then rules for specific predictions, explaining which features are responsible for the decision.",Rule Extraction,Decision Rules,No,Yes,Model-Agnostic,Generating rules to explain individual predictions in text classification.,Decision Rules; Local Scope; Model-Agnostic; Rule Extraction
RuleFit,Combines decision rules with linear models to provide interpretable models capturing non-linear patterns.,Rule Extraction,Decision Rules; Decision Trees,Yes,No,Model-Agnostic,Building interpretable models for predicting customer churn with rule-based explanations.,Decision Rules; Decision Trees; Global Scope; Model-Agnostic; Rule Extraction
Monte Carlo Dropout,Uses dropout at inference time in deep learning models to estimate uncertainty by approximating Bayesian inference.,Uncertainty and Reliability,Confidence Estimation,Yes,No,Model-Specific,Estimating prediction uncertainty in medical diagnosis models.,Confidence Estimation; Global Scope; Model-Specific; Uncertainty
ODIN (Out-of-DIstribution detector for Neural networks),Detects out-of-distribution samples in neural networks by applying temperature scaling and input perturbations.,Uncertainty and Reliability,Out-of-Distribution Detection,Yes,No,Model-Specific,Identifying when an image classifier encounters novel inputs.,Global Scope; Model-Specific; Out-of-Distribution Detection; Uncertainty
Permutation Tests,Estimates uncertainty by permuting data labels and calculating test statistics to create a null distribution in non-parametric methods.,Uncertainty and Reliability,Uncertainty Quantification,Yes,No,Model-Agnostic,Assessing the significance of model predictions in hypothesis testing.,Global Scope; Model-Agnostic; Uncertainty; Uncertainty Quantification
"Fairness Metrics (e.g., Equalized Odds, Demographic Parity)",Evaluates models for fairness by measuring disparities in predictions across different demographic groups.,Fairness Explanations,Bias Detection and Mitigation,Yes,No,Model-Agnostic,Ensuring a hiring model does not discriminate based on gender or ethnicity.,Bias Mitigation; Fairness; Global Scope; Model-Agnostic
???,???,Fairness Explanations,Fairness Metrics Visualisation,No,No,???,???,Fairness; Fairness Metrics Visualisation
Model Pruning,"Simplifies neural networks by removing less important weights or neurons, reducing complexity while retaining performance.",Model Simplification,Model Pruning,Yes,No,Model-Specific,Reducing model size for deployment on mobile devices without significant loss in accuracy.,Global Scope; Model Pruning; Model Simplification; Model-Specific
Knowledge Distillation,"Trains a simpler 'student' model to replicate the behaviour of a complex 'teacher' model, resulting in a more interpretable model.",Model Simplification,Model Distillation,Yes,No,Model-Agnostic,Simplifying a deep neural network for faster inference in real-time applications.,Global Scope; Model Distillation; Model Simplification; Model-Agnostic
Attention Visualisation in Transformers,Visualises attention weights in transformer-based models to show how the model focuses on different input parts during prediction. Attention weights also indicate feature importance.,Visualisation Techniques; Feature Analysis,Model Behaviour Visualisation; Importance and Attribution,No,Yes,Model-Specific,Understanding which words a transformer model focuses on during machine translation or summarisation tasks.,Attribution; Feature Importance; Local Scope; Model-Specific; Visualisation
Neuron Activation Analysis,Analyses activation patterns of neurons in large language models (LLMs) to interpret their roles and the concepts they represent.,Feature Analysis,Importance and Attribution,Yes,Yes,Model-Specific,Identifying neurons responsible for syntax or semantics in language models.,Attribution; Feature Importance; Global Scope; Local Scope; Model-Specific
Prompt Sensitivity Analysis,Studies how variations in input prompts affect LLM outputs to understand model behaviour and sensitivity.,Example-Based Methods,Prototype and Criticism Methods,No,Yes,Model-Specific,Evaluating how different phrasings influence an LLM's answers in question-answering tasks.,Example-Based; Local Scope; Model-Specific
Causal Mediation Analysis in Language Models,Investigates causal relationships within LLMs by assessing how interventions on specific components affect outputs.,Example-Based Methods,Causal Analysis,Yes,Yes,Model-Specific,Understanding how adjusting embeddings changes model responses in language generation tasks.,Causal Analysis; Example-Based; Global Scope; Local Scope; Model-Specific
Feature Attribution with Integrated Gradients in NLP,"Applies Integrated Gradients to attribute importance of input tokens in LLMs for specific predictions, often producing visualisations.",Feature Analysis; Visualisation Techniques,Importance and Attribution; Feature Visualisation,No,Yes,Model-Specific,Identifying words influencing text sentiment classification or topic modeling.,Attribution; Feature Importance; Feature Visualisation; Local Scope; Model-Specific; Visualisation
Concept Activation Vectors (CAVs),Represents human-understandable concepts as vectors in the model's latent space to analyse their influence on predictions. Can overlap with example-based methods.,Feature Analysis; Example-Based Methods,Importance and Attribution; Prototype and Criticism Methods,Yes,Yes,Model-Specific,"Assessing how concepts like ""negativity"" affect language model outputs.",Attribution; Example-Based; Feature Importance; Global Scope; Local Scope; Model-Specific
In-Context Learning Analysis,"Examines how LLMs learn from examples provided in the input prompt, revealing capacity for few-shot learning.",Example-Based Methods,Prototype and Criticism Methods,No,Yes,Model-Specific,Analysing the effect of examples on an LLM's ability to perform a new task like translation.,Example-Based; Local Scope; Model-Specific
