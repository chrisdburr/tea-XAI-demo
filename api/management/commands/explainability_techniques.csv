Technique Name,Description,Category,Sub-Category,Model Dependency,Example Use Case,Scope Global,Scope Local
SHAP (SHapley Additive exPlanations),"Assigns importance values to each feature by computing their contribution to individual predictions, based on Shapley values from cooperative game theory.",Feature Analysis,Importance and Attribution,Model-Agnostic,Explaining individual predictions in complex models like neural networks or ensemble models.,Yes,Yes
Permutation Importance,Evaluates feature importance by measuring the decrease in model accuracy when a feature's values are randomly shuffled.,Feature Analysis,Importance and Attribution,Model-Agnostic,"Assessing feature importance in models where coefficients are not available, such as tree-based models.",Yes,No
Mean Decrease Impurity (MDI),Calculates feature importance in tree-based models by measuring how much each feature decreases impurity across all trees.,Feature Analysis,Importance and Attribution,Model-Specific,Determining important features in Random Forest classification tasks.,Yes,No
Gini Importance,Measures the total reduction of Gini impurity brought by a feature across all nodes and trees in decision trees and Random Forests.,Feature Analysis,Importance and Attribution,Model-Specific,Selecting important features when building tree-based classification models.,Yes,No
Coefficient Magnitudes (in Linear Models),"Uses the absolute values of coefficients in linear models to represent feature importance, indicating the strength and direction of relationships.",Feature Analysis,Importance and Attribution,Model-Specific,Interpreting which features influence housing price predictions in linear regression.,Yes,No
Integrated Gradients,Attributes feature importance by integrating gradients of the model's output with respect to inputs along a path from a baseline to the actual input.,Feature Analysis,Importance and Attribution,Model-Specific,Understanding pixel contributions in image classification with deep neural networks.,No,Yes
DeepLIFT,"Tracks changes in the output relative to a reference input, decomposing contributions from individual neurons to the final prediction in deep learning models.",Feature Analysis,Importance and Attribution,Model-Specific,Explaining why a neural network classifies an image as a specific object by tracing neuron activations.,No,Yes
Layer-wise Relevance Propagation (LRP),"Explains predictions by backpropagating relevance scores from the output layer to input features, distributing the prediction score layer by layer.",Feature Analysis,Importance and Attribution,Model-Specific,Visualizing important regions in medical images for disease diagnosis using deep learning models.,No,Yes
"Variable Importance in Random Forests (MDA, MDG)",Calculates feature importance by measuring the Mean Decrease Accuracy or Mean Decrease Gini when a feature is excluded from Random Forest models.,Feature Analysis,Importance and Attribution,Model-Specific,Identifying key predictors in a Random Forest model for credit scoring.,Yes,No
Contextual Decomposition,Interprets neural networks by decomposing activations to explain predictions based on contributions of individual features or groups.,Feature Analysis,Importance and Attribution,Model-Specific,Explaining sentiment predictions in text by attributing scores to words or phrases.,No,Yes
Taylor Decomposition,Decomposes predictions into contributions from individual features using a Taylor series expansion of the model's prediction function.,Feature Analysis,Importance and Attribution,Model-Specific,Attributing feature contributions in complex models for specific predictions.,No,Yes
Sobol Indices,Quantifies the contribution of individual variables and their interactions to the output variance in sensitivity analysis.,Feature Analysis,Interaction Analysis,Model-Agnostic,Understanding parameter impacts in environmental modeling outputs.,Yes,No
Feature Interaction Detection (H-statistic),Measures feature interaction by comparing joint contributions to the model with the sum of individual contributions.,Feature Analysis,Interaction Analysis,Model-Agnostic,Identifying significant interactions in healthcare predictive models.,Yes,No
LIME (Local Interpretable Model-Agnostic Explanations),Generates local surrogate models that approximate complex model behaviour around a specific instance using interpretable models like linear models.,Model Approximation,Local Surrogates,Model-Agnostic,Explaining why a customer was denied a loan by approximating the model's decision locally.,No,Yes
Ridge Regression Surrogates,"Uses Ridge Regression as a surrogate to approximate global behaviour of complex models, balancing simplicity and interpretability with regularisation.",Model Approximation,Global Surrogates,Model-Agnostic,Summarising complex model behaviour for regulatory reporting in finance.,Yes,No
Partial Dependence Plots (PDP),"Visualises the relationship between one or two features and the predicted outcome, averaging out effects of other features.",Visualisation Techniques,Feature Visualisation,Model-Agnostic,Understanding how changes in age affect predicted disease risk in medical models.,Yes,No
Accumulated Local Effects (ALE) Plots,"Similar to PDPs but account for feature interactions, providing accurate insights when features are correlated.",Visualisation Techniques,Feature Visualisation,Model-Agnostic,Exploring the effect of house size on price predictions in real estate models with correlated features.,Yes,No
Individual Conditional Expectation (ICE) Plots,"Shows how a feature affects predictions for individual instances, highlighting heterogeneous effects across data points.",Visualisation Techniques,Feature Visualisation,Model-Agnostic,Visualising how customers' predicted spending changes with income in consumer behaviour models.,No,Yes
Saliency Maps,Highlights important pixels in input images that most influence the output prediction in computer vision models.,Visualisation Techniques,Model Behaviour Visualisation,Model-Specific,Identifying regions contributing to tumor diagnosis in medical images.,No,Yes
Grad-CAM (Gradient-weighted Class Activation Mapping),Uses gradients to produce heatmaps highlighting image regions that contribute most to the model's output.,Visualisation Techniques,Model Behaviour Visualisation,Model-Specific,Visualising parts of an image leading to a 'dog' classification in image recognition models.,No,Yes
Occlusion Sensitivity,Measures prediction changes by systematically occluding parts of the input to identify important regions or features.,Visualisation Techniques,Model Behaviour Visualisation,Model-Specific,Understanding which words affect sentiment prediction by masking them in NLP models.,No,Yes
Attention Mechanisms in Neural Networks,"Visualises attention weights in models like transformers, highlighting important input parts for predictions.",Visualisation Techniques,Model Behaviour Visualisation,Model-Specific,Analysing which words a transformer model focuses on during machine translation tasks.,No,Yes
Factor Analysis,"Reduces dimensionality by identifying latent factors explaining observed variability, aiding in data interpretation.",Model Simplification,Dimensionality Reduction,Model-Agnostic,Discovering underlying factors in psychological survey data for social science research.,Yes,No
Principal Component Analysis (PCA),"Reduces dimensionality by projecting data onto directions of maximum variance, simplifying data while retaining important information.",Visualisation Techniques,Dimensionality Reduction Visualisation,Model-Agnostic,Visualising high-dimensional gene expression data in bioinformatics.,Yes,No
t-SNE,"A non-linear technique that visualises high-dimensional data in 2D or 3D, preserving local relationships between points.",Visualisation Techniques,Dimensionality Reduction Visualisation,Model-Agnostic,Visualizing clusters in high-dimensional word embeddings.,Yes,No
UMAP,A non-linear technique similar to t-SNE but better at preserving global data structure.,Visualisation Techniques,Dimensionality Reduction Visualisation,Model-Agnostic,Visualising patterns in user behaviour data for marketing analysis.,Yes,No
Prototype and Criticism Models,Identifies representative (prototypes) and non-representative (criticisms) examples to summarise and highlight model behaviour.,Example-Based Methods,Prototype and Criticism Methods,Model-Agnostic,Selecting representative customer profiles for targeted marketing.,Yes,No
Influence Functions,Measures the impact of training examples on model predictions to identify influential data points.,Example-Based Methods,Prototype and Criticism Methods,Model-Agnostic,Debugging model predictions by identifying influential training data points.,Yes,No
Contrastive Explanation Method (CEM),"Generates explanations by identifying minimal input changes that result in different outcomes, offering counterfactual reasoning.",Example-Based Methods,Counterfactual Explanations,Model-Agnostic,Explaining loan rejections by showing what changes would lead to approval.,No,Yes
"Bayesian Networks (e.g., bnlearn)",Probabilistic graphical models representing variables and their conditional dependencies for causal reasoning.,Example-Based Methods,Causal Analysis,Model-Specific,Modeling causal relationships in gene regulatory networks.,Yes,No
ANCHOR,"Provides high-precision if-then rules for specific predictions, explaining which features are responsible for the decision.",Rule Extraction,Decision Rules,Model-Agnostic,Generating rules to explain individual predictions in text classification.,No,Yes
RuleFit,Combines decision rules with linear models to provide interpretable models capturing non-linear patterns.,Rule Extraction,Decision Rules,Model-Agnostic,Building interpretable models for predicting customer churn with rule-based explanations.,Yes,No
Monte Carlo Dropout,Uses dropout at inference time in deep learning models to estimate uncertainty by approximating Bayesian inference.,Uncertainty and Reliability,Confidence Estimation,Model-Specific,Estimating prediction uncertainty in medical diagnosis models.,Yes,No
ODIN (Out-of-DIstribution detector for Neural networks),Detects out-of-distribution samples in neural networks by applying temperature scaling and input perturbations.,Uncertainty and Reliability,Out-of-Distribution Detection,Model-Specific,Identifying when an image classifier encounters novel inputs.,Yes,No
Permutation Tests,Estimates uncertainty by permuting data labels and calculating test statistics to create a null distribution in non-parametric methods.,Uncertainty and Reliability,Uncertainty Quantification,Model-Agnostic,Assessing the significance of model predictions in hypothesis testing.,Yes,No
"Fairness Metrics (e.g., Equalized Odds, Demographic Parity)",Evaluates models for fairness by measuring disparities in predictions across different demographic groups.,Fairness Explanations,Bias Detection and Mitigation,Model-Agnostic,Ensuring a hiring model does not discriminate based on gender or ethnicity.,Yes,No
Model Pruning,"Simplifies neural networks by removing less important weights or neurons, reducing complexity while retaining performance.",Model Simplification,Model Pruning,Model-Specific,Reducing model size for deployment on mobile devices without significant loss in accuracy.,Yes,No
Knowledge Distillation,"Trains a simpler 'student' model to replicate the behaviour of a complex 'teacher' model, resulting in a more interpretable model.",Model Simplification,Model Distillation,Model-Agnostic,Simplifying a deep neural network for faster inference in real-time applications.,Yes,No
Attention Visualisation in Transformers,Visualises attention weights in transformer-based models to show how the model focuses on different input parts during prediction.,Visualisation Techniques,Model Behaviour Visualisation,Model-Specific,Understanding which words a transformer model focuses on during machine translation tasks.,No,Yes
Neuron Activation Analysis,Analyses activation patterns of neurons in large language models (LLMs) to interpret their roles and the concepts they represent.,Feature Analysis,Importance and Attribution,Model-Specific,Identifying neurons responsible for syntax or semantics in language models.,Yes,Yes
Prompt Sensitivity Analysis,Studies how variations in input prompts affect LLM outputs to understand model behaviour and sensitivity.,Example-Based Methods,Prototype and Criticism Methods,Model-Specific,Evaluating how different phrasings influence an LLM's answers in question-answering tasks.,No,Yes
Causal Mediation Analysis in Language Models,Investigates causal relationships within LLMs by assessing how interventions on specific components affect outputs.,Example-Based Methods,Causal Analysis,Model-Specific,Understanding how adjusting embeddings changes model responses in language generation tasks.,Yes,Yes
Feature Attribution with Integrated Gradients in NLP,"Applies Integrated Gradients to attribute importance of input tokens in LLMs for specific predictions, often producing visualisations.",Feature Analysis,Importance and Attribution,Model-Specific,Identifying words influencing text sentiment classification or topic modeling.,No,Yes
Concept Activation Vectors (CAVs),Represents human-understandable concepts as vectors in the model's latent space to analyse their influence on predictions.,Feature Analysis,Importance and Attribution,Model-Specific,"Assessing how concepts like ""negativity"" affect language model outputs.",Yes,Yes
In-Context Learning Analysis,"Examines how LLMs learn from examples provided in the input prompt, revealing capacity for few-shot learning.",Example-Based Methods,Prototype and Criticism Methods,Model-Specific,Analysing the effect of examples on an LLM's ability to perform a new task like translation.,No,Yes
